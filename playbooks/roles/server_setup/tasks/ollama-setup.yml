---
- name: Create Ollama media directories
  ansible.builtin.file:
    path: /mnt/media-nvm/Ollama
    state: directory
    mode: '0755'
    owner: '{{ superuser_name }}'
    group: '{{ superuser_name }}'

- name: Pull and run Ollama Docker image
  community.docker.docker_container:
    name: ollama
    image: "ollama/ollama:0.12.0-rc0-rocm"
    state: started
    recreate: true
    memory: "8G"
    cpus: "4"
    restart_policy: "unless-stopped"
    labels:
      sablier.enable: "true"
      sablier.group: "ollama"
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    networks:
      - name: sleepers
    volumes:
      - /mnt/media-nvm/Ollama:/root/.ollama

- name: Pull and run OpenwebUI
  community.docker.docker_container:
    name: openwebui
    image: "ghcr.io/open-webui/open-webui:v0.6.30"
    state: started
    recreate: true
    restart_policy: "unless-stopped"
    labels:
      sablier.enable: "true"
      sablier.group: "ollama"
    env:
      OLLAMA_BASE_URL: http://ollama:11434
    networks:
      - name: sleepers
    volumes:
      - /mnt/media-nvm/OpenWebUI:/app/backend/data

- name: Load Ollama Model Loaders
  community.docker.docker_container:
    name: ollama-model-loader
    image: "alpine/curl:8.14.1"
    state: started
    recreate: true
    command: sleep infinity
    restart_policy: "unless-stopped"
    labels:
      sablier.enable: "true"
      sablier.group: "ollama"
    networks:
      - name: sleepers

- name: Pull model into Ollama
  community.docker.docker_container_exec:
    container: ollama-model-loader
    command: >
      curl --location 'http://ollama:11434/api/pull' --data '{"name": "llama3.2", "stream": true}'

- name: Load model into Ollama
  community.docker.docker_container_exec:
    container: ollama-model-loader
    command: >
      curl --fail --location 'http://ollama:11434/api/generate' --data '{"model": "llama3.2"}' --header 'Content-Type: application/json'

...